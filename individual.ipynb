{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"!\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip! install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB,ComplementNB,MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier,LocalOutlierFactor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\Bhavya\\Desktop\\HateSpeechDataset\\labeled_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_and_extract_rt_username(text):\n",
    "    rt_pattern = re.search(r'RT\\s+@[\\w]+:', text)\n",
    "    if rt_pattern:\n",
    "        extracted_pattern = rt_pattern.group()\n",
    "        text_without_rt = text.replace(extracted_pattern, '')\n",
    "        return text_without_rt, extracted_pattern\n",
    "    else:\n",
    "        return text, None\n",
    "\n",
    "def extract_hashtags(text):\n",
    "    hashtags = re.findall(r'#\\w+', text)\n",
    "    return hashtags\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    return text.encode('ascii', 'ignore').decode()\n",
    "\n",
    "def extract_urls(text):\n",
    "    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "    return urls\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    s = re.sub(r'[^\\w\\s]', '', s)\n",
    "    return s\n",
    "\n",
    "def remove_stopwords(s):\n",
    "    s = ' '.join(word for word in s.split() if word not in stop_words)\n",
    "    return s\n",
    "\n",
    "def remove_symbols(s):\n",
    "    s = re.sub(r'[^a-zA-Z\\s]', '', s)\n",
    "    return s\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def stem_text(s):\n",
    "    s = ' '.join(stemmer.stem(word) for word in s.split())\n",
    "    return s\n",
    "def lemmatize_text(s):\n",
    "    s = ' '.join(lemmatizer.lemmatize(word) for word in s.split())\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\bhavya\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\bhavya\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\bhavya\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bhavya\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bhavya\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhavya\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Bhavya\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hashtags'] = df['tweet'].apply(extract_hashtags)\n",
    "df['text_without_hashtag'] = df['tweet'].apply(lambda x: re.sub(r'#\\w+', '', x))\n",
    "df['text_without_hashtag_rt'], df['rt_username'] = zip(*df['text_without_hashtag'].apply(remove_and_extract_rt_username))\n",
    "df['urls'] = df['text_without_hashtag_rt'].apply(extract_urls)\n",
    "df['text_without_urls'] = df['text_without_hashtag_rt'].apply(remove_urls)\n",
    "df['cleaned_text'] = df['text_without_hashtag_rt'].apply(remove_urls)\n",
    "df['cleaned_text2']=df['cleaned_text'].str.replace('[^\\w\\s]','')\n",
    "df['cleaned_text3']=df['cleaned_text2'].apply(str.lower)\n",
    "df['cleaned_text4']=df['cleaned_text3'].apply(remove_symbols)\n",
    "df['stemmed']=df['cleaned_text4'].apply(stem_text)\n",
    "df['lemmatized']=df['cleaned_text4'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>text_without_hashtag</th>\n",
       "      <th>text_without_hashtag_rt</th>\n",
       "      <th>rt_username</th>\n",
       "      <th>urls</th>\n",
       "      <th>text_without_urls</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_text2</th>\n",
       "      <th>cleaned_text3</th>\n",
       "      <th>cleaned_text4</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>[]</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>!!!  As a woman you shouldn't complain about c...</td>\n",
       "      <td>RT @mayasolovely:</td>\n",
       "      <td>[]</td>\n",
       "      <td>!!!  As a woman you shouldn't complain about c...</td>\n",
       "      <td>!!!  As a woman you shouldn't complain about c...</td>\n",
       "      <td>!!!  As a woman you shouldn't complain about c...</td>\n",
       "      <td>!!!  as a woman you shouldn't complain about c...</td>\n",
       "      <td>as a woman you shouldnt complain about clean...</td>\n",
       "      <td>as a woman you shouldnt complain about clean u...</td>\n",
       "      <td>a a woman you shouldnt complain about cleaning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>[]</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>!!!!!  boy dats cold...tyga dwn bad for cuffin...</td>\n",
       "      <td>RT @mleew17:</td>\n",
       "      <td>[]</td>\n",
       "      <td>!!!!!  boy dats cold...tyga dwn bad for cuffin...</td>\n",
       "      <td>!!!!!  boy dats cold...tyga dwn bad for cuffin...</td>\n",
       "      <td>!!!!!  boy dats cold...tyga dwn bad for cuffin...</td>\n",
       "      <td>!!!!!  boy dats cold...tyga dwn bad for cuffin...</td>\n",
       "      <td>boy dats coldtyga dwn bad for cuffin dat hoe...</td>\n",
       "      <td>boy dat coldtyga dwn bad for cuffin dat hoe in...</td>\n",
       "      <td>boy dat coldtyga dwn bad for cuffin dat hoe in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>[]</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!!  You ever f...</td>\n",
       "      <td>RT @80sbaby4life:</td>\n",
       "      <td>[]</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!!  You ever f...</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!!  You ever f...</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!!  You ever f...</td>\n",
       "      <td>!!!!!!! rt @urkindofbrand dawg!!!!  you ever f...</td>\n",
       "      <td>rt urkindofbrand dawg  you ever fuck a bitch ...</td>\n",
       "      <td>rt urkindofbrand dawg you ever fuck a bitch an...</td>\n",
       "      <td>rt urkindofbrand dawg you ever fuck a bitch an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>!!!!!!!!!  @viva_based she look like a tranny</td>\n",
       "      <td>RT @C_G_Anderson:</td>\n",
       "      <td>[]</td>\n",
       "      <td>!!!!!!!!!  @viva_based she look like a tranny</td>\n",
       "      <td>!!!!!!!!!  @viva_based she look like a tranny</td>\n",
       "      <td>!!!!!!!!!  @viva_based she look like a tranny</td>\n",
       "      <td>!!!!!!!!!  @viva_based she look like a tranny</td>\n",
       "      <td>vivabased she look like a tranny</td>\n",
       "      <td>vivabas she look like a tranni</td>\n",
       "      <td>vivabased she look like a tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>[#57361]</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>!!!!!!!!!!!!!  The shit you hear about me migh...</td>\n",
       "      <td>RT @ShenikaRoberts:</td>\n",
       "      <td>[]</td>\n",
       "      <td>!!!!!!!!!!!!!  The shit you hear about me migh...</td>\n",
       "      <td>!!!!!!!!!!!!!  The shit you hear about me migh...</td>\n",
       "      <td>!!!!!!!!!!!!!  The shit you hear about me migh...</td>\n",
       "      <td>!!!!!!!!!!!!!  the shit you hear about me migh...</td>\n",
       "      <td>the shit you hear about me might be true or ...</td>\n",
       "      <td>the shit you hear about me might be true or it...</td>\n",
       "      <td>the shit you hear about me might be true or it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  Hashtags  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...        []   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...        []   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...        []   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...        []   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  [#57361]   \n",
       "\n",
       "                                text_without_hashtag  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                             text_without_hashtag_rt          rt_username  \\\n",
       "0  !!!  As a woman you shouldn't complain about c...    RT @mayasolovely:   \n",
       "1  !!!!!  boy dats cold...tyga dwn bad for cuffin...         RT @mleew17:   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!!  You ever f...    RT @80sbaby4life:   \n",
       "3      !!!!!!!!!  @viva_based she look like a tranny    RT @C_G_Anderson:   \n",
       "4  !!!!!!!!!!!!!  The shit you hear about me migh...  RT @ShenikaRoberts:   \n",
       "\n",
       "  urls                                  text_without_urls  \\\n",
       "0   []  !!!  As a woman you shouldn't complain about c...   \n",
       "1   []  !!!!!  boy dats cold...tyga dwn bad for cuffin...   \n",
       "2   []  !!!!!!! RT @UrKindOfBrand Dawg!!!!  You ever f...   \n",
       "3   []      !!!!!!!!!  @viva_based she look like a tranny   \n",
       "4   []  !!!!!!!!!!!!!  The shit you hear about me migh...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  !!!  As a woman you shouldn't complain about c...   \n",
       "1  !!!!!  boy dats cold...tyga dwn bad for cuffin...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!!  You ever f...   \n",
       "3      !!!!!!!!!  @viva_based she look like a tranny   \n",
       "4  !!!!!!!!!!!!!  The shit you hear about me migh...   \n",
       "\n",
       "                                       cleaned_text2  \\\n",
       "0  !!!  As a woman you shouldn't complain about c...   \n",
       "1  !!!!!  boy dats cold...tyga dwn bad for cuffin...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!!  You ever f...   \n",
       "3      !!!!!!!!!  @viva_based she look like a tranny   \n",
       "4  !!!!!!!!!!!!!  The shit you hear about me migh...   \n",
       "\n",
       "                                       cleaned_text3  \\\n",
       "0  !!!  as a woman you shouldn't complain about c...   \n",
       "1  !!!!!  boy dats cold...tyga dwn bad for cuffin...   \n",
       "2  !!!!!!! rt @urkindofbrand dawg!!!!  you ever f...   \n",
       "3      !!!!!!!!!  @viva_based she look like a tranny   \n",
       "4  !!!!!!!!!!!!!  the shit you hear about me migh...   \n",
       "\n",
       "                                       cleaned_text4  \\\n",
       "0    as a woman you shouldnt complain about clean...   \n",
       "1    boy dats coldtyga dwn bad for cuffin dat hoe...   \n",
       "2   rt urkindofbrand dawg  you ever fuck a bitch ...   \n",
       "3                   vivabased she look like a tranny   \n",
       "4    the shit you hear about me might be true or ...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  as a woman you shouldnt complain about clean u...   \n",
       "1  boy dat coldtyga dwn bad for cuffin dat hoe in...   \n",
       "2  rt urkindofbrand dawg you ever fuck a bitch an...   \n",
       "3                     vivabas she look like a tranni   \n",
       "4  the shit you hear about me might be true or it...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  a a woman you shouldnt complain about cleaning...  \n",
       "1  boy dat coldtyga dwn bad for cuffin dat hoe in...  \n",
       "2  rt urkindofbrand dawg you ever fuck a bitch an...  \n",
       "3                   vivabased she look like a tranny  \n",
       "4  the shit you hear about me might be true or it...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models:\n",
      "\n",
      "model Logistic Regression trained\n",
      "model Multinomial Naive Bayes trained\n",
      "model Complement Naive Bayes trained\n",
      "model KMeans trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model XGB trained\n",
      "model Support Vector Machine trained\n",
      "model Decision Tree trained\n",
      "model kNN trained\n",
      "model SGD trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model adaboost trained\n",
      "model Random Forest trained\n",
      "Test Set Prediction:\n",
      "\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.25      0.33       429\n",
      "           1       0.93      0.95      0.94      5757\n",
      "           2       0.84      0.86      0.85      1249\n",
      "\n",
      "    accuracy                           0.90      7435\n",
      "   macro avg       0.75      0.69      0.71      7435\n",
      "weighted avg       0.89      0.90      0.89      7435\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.07      0.12       429\n",
      "           1       0.87      0.97      0.92      5757\n",
      "           2       0.85      0.59      0.69      1249\n",
      "\n",
      "    accuracy                           0.86      7435\n",
      "   macro avg       0.68      0.55      0.58      7435\n",
      "weighted avg       0.83      0.86      0.83      7435\n",
      "\n",
      "Complement Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.27      0.30       429\n",
      "           1       0.91      0.92      0.92      5757\n",
      "           2       0.75      0.75      0.75      1249\n",
      "\n",
      "    accuracy                           0.86      7435\n",
      "   macro avg       0.66      0.65      0.65      7435\n",
      "weighted avg       0.85      0.86      0.85      7435\n",
      "\n",
      "KMeans\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.23      0.09       429\n",
      "           1       0.80      0.79      0.80      5757\n",
      "           2       0.00      0.00      0.00      1249\n",
      "\n",
      "    accuracy                           0.63      7435\n",
      "   macro avg       0.29      0.34      0.30      7435\n",
      "weighted avg       0.62      0.63      0.62      7435\n",
      "\n",
      "XGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.23      0.32       429\n",
      "           1       0.93      0.95      0.94      5757\n",
      "           2       0.83      0.90      0.86      1249\n",
      "\n",
      "    accuracy                           0.90      7435\n",
      "   macro avg       0.76      0.70      0.71      7435\n",
      "weighted avg       0.89      0.90      0.89      7435\n",
      "\n",
      "Support Vector Machine\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.20      0.26       429\n",
      "           1       0.92      0.94      0.93      5757\n",
      "           2       0.78      0.81      0.79      1249\n",
      "\n",
      "    accuracy                           0.87      7435\n",
      "   macro avg       0.68      0.65      0.66      7435\n",
      "weighted avg       0.86      0.87      0.87      7435\n",
      "\n",
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.33      0.35       429\n",
      "           1       0.94      0.93      0.93      5757\n",
      "           2       0.81      0.88      0.84      1249\n",
      "\n",
      "    accuracy                           0.88      7435\n",
      "   macro avg       0.71      0.71      0.71      7435\n",
      "weighted avg       0.88      0.88      0.88      7435\n",
      "\n",
      "kNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.27      0.27       429\n",
      "           1       0.86      0.94      0.90      5757\n",
      "           2       0.71      0.41      0.52      1249\n",
      "\n",
      "    accuracy                           0.81      7435\n",
      "   macro avg       0.61      0.54      0.56      7435\n",
      "weighted avg       0.80      0.81      0.80      7435\n",
      "\n",
      "SGD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.07      0.12       429\n",
      "           1       0.93      0.95      0.94      5757\n",
      "           2       0.79      0.94      0.85      1249\n",
      "\n",
      "    accuracy                           0.90      7435\n",
      "   macro avg       0.75      0.65      0.64      7435\n",
      "weighted avg       0.88      0.90      0.88      7435\n",
      "\n",
      "adaboost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.14      0.22       429\n",
      "           1       0.93      0.94      0.93      5757\n",
      "           2       0.75      0.91      0.82      1249\n",
      "\n",
      "    accuracy                           0.89      7435\n",
      "   macro avg       0.72      0.66      0.66      7435\n",
      "weighted avg       0.87      0.89      0.87      7435\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.12      0.19       429\n",
      "           1       0.88      0.97      0.92      5757\n",
      "           2       0.87      0.65      0.74      1249\n",
      "\n",
      "    accuracy                           0.87      7435\n",
      "   macro avg       0.74      0.58      0.62      7435\n",
      "weighted avg       0.85      0.87      0.85      7435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------VotingClassifier--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.50265   0.22145   0.30744       429\n",
      "           1    0.92948   0.95241   0.94080      5757\n",
      "           2    0.82999   0.89512   0.86133      1249\n",
      "\n",
      "    accuracy                        0.90061      7435\n",
      "   macro avg    0.75404   0.68966   0.70319      7435\n",
      "weighted avg    0.88814   0.90061   0.89091      7435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=df['cleaned_text4'].values\n",
    "vectorizer = CountVectorizer()  \n",
    "x = vectorizer.fit_transform(x)\n",
    "y=df['class']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=51,stratify=y)\n",
    "models = dict()\n",
    "results=dict()\n",
    "models['Logistic Regression'] = LogisticRegression(max_iter=5000)\n",
    "models['Multinomial Naive Bayes'] = MultinomialNB()\n",
    "models['Complement Naive Bayes'] = ComplementNB(force_alpha=True)\n",
    "models['KMeans'] = KMeans(n_clusters=2, n_init=10, random_state=59)\n",
    "models['XGB']= XGBClassifier(n_estimators=500)\n",
    "models['Support Vector Machine'] = SVC(kernel = 'sigmoid', gamma='scale',probability=True)\n",
    "models['Decision Tree'] = DecisionTreeClassifier(max_depth=100)\n",
    "models['kNN'] = KNeighborsClassifier()\n",
    "models['SGD']=SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=100, tol=None)\n",
    "models['adaboost']=AdaBoostClassifier()\n",
    "models['Random Forest'] = RandomForestClassifier(n_estimators=100)\n",
    "print(\"Training Models:\\n\")\n",
    "for model in models:\n",
    "        models[model].fit(x_train,y_train)\n",
    "        print(\"model \"+str(model)+\" trained\")\n",
    "print(\"Test Set Prediction:\\n\")\n",
    "model_names,accuracies,precisions_w,recalls_w,f1_scores_w,precisions_m,recalls_m,f1_scores_m = [],[],[],[],[],[],[],[]\n",
    "for i in models:\n",
    "        print(i)\n",
    "        y_pred=models[i].predict(x_test)\n",
    "        print(classification_report(y_test,y_pred))\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        if i!='SGD':\n",
    "                results[models[i]]=accuracy\n",
    "        precision_w = precision_score(y_test, y_pred,average='weighted')\n",
    "        recall_w = recall_score(y_test, y_pred,average='weighted')\n",
    "        f1_w = f1_score(y_test, y_pred,average='weighted')\n",
    "        precision_m = precision_score(y_test, y_pred,average='macro')\n",
    "        recall_m = recall_score(y_test, y_pred,average='macro')\n",
    "        f1_m = f1_score(y_test, y_pred,average='macro')\n",
    "        model_names.append(i)\n",
    "        accuracies.append(accuracy)\n",
    "        precisions_w.append(precision_w)\n",
    "        recalls_w.append(recall_w)\n",
    "        f1_scores_w.append(f1_w)\n",
    "        precisions_m.append(precision_m)\n",
    "        recalls_m.append(recall_m)\n",
    "        f1_scores_m.append(f1_m)\n",
    "top_3_keys_bow = sorted(results, key=lambda k: results[k], reverse=True)[:3]\n",
    "c1=top_3_keys_bow[0]\n",
    "c2=top_3_keys_bow[1]\n",
    "c3=top_3_keys_bow[2]\n",
    "models['ensemble voting'] = VotingClassifier (estimators=[('clf1',c1), ('clf2',c2),('clf3',c3)], voting='soft')\n",
    "models['ensemble voting'].fit(x_train, y_train)\n",
    "y_pred = models['ensemble voting'].predict(x_test)\n",
    "print('-'*20+'VotingClassifier'+'-'*20)\n",
    "print(classification_report(y_test, y_pred,digits=5))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_w = precision_score(y_test, y_pred,average='weighted')\n",
    "recall_w = recall_score(y_test, y_pred,average='weighted')\n",
    "f1_w = f1_score(y_test, y_pred,average='weighted')\n",
    "precision_m = precision_score(y_test, y_pred,average='macro')\n",
    "recall_m = recall_score(y_test, y_pred,average='macro')\n",
    "f1_m = f1_score(y_test, y_pred,average='macro')\n",
    "model_names.append('ensemble voting')\n",
    "accuracies.append(accuracy)\n",
    "precisions_w.append(precision_w)\n",
    "recalls_w.append(recall_w)\n",
    "f1_scores_w.append(f1_w)\n",
    "precisions_m.append(precision_m)\n",
    "recalls_m.append(recall_m)\n",
    "f1_scores_m.append(f1_m)\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model Name': model_names,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision Weighted': precisions_w,\n",
    "    'Recall Weighted': recalls_w,\n",
    "    'F1-Score Weighted': f1_scores_w,\n",
    "    'Precision Macro': precisions_m,\n",
    "    'Recall Macro': recalls_m,\n",
    "    'F1-Score Macro': f1_scores_m\n",
    "})\n",
    "metrics_df.sort_values(by=['Accuracy'], ascending=False, inplace=True)\n",
    "metrics_df.to_csv(\"Bow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models:\n",
      "\n",
      "model Linear Regression trained\n",
      "model Multinomial Naive Bayes trained\n",
      "model Complement Naive Bayes trained\n",
      "model KMeans trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model XGB trained\n",
      "model Support Vector Machine trained\n",
      "model Decision Tree trained\n",
      "model kNN trained\n",
      "model SGD trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model adaboost trained\n",
      "model Random Forest trained\n",
      "Test Set Prediction:\n",
      "\n",
      "Linear Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.12      0.20       429\n",
      "           1       0.90      0.98      0.93      5757\n",
      "           2       0.87      0.76      0.81      1249\n",
      "\n",
      "    accuracy                           0.89      7435\n",
      "   macro avg       0.80      0.62      0.65      7435\n",
      "weighted avg       0.88      0.89      0.87      7435\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       429\n",
      "           1       0.79      1.00      0.88      5757\n",
      "           2       0.95      0.08      0.15      1249\n",
      "\n",
      "    accuracy                           0.79      7435\n",
      "   macro avg       0.58      0.36      0.34      7435\n",
      "weighted avg       0.77      0.79      0.71      7435\n",
      "\n",
      "Complement Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.17      0.20       429\n",
      "           1       0.86      0.95      0.90      5757\n",
      "           2       0.79      0.49      0.61      1249\n",
      "\n",
      "    accuracy                           0.83      7435\n",
      "   macro avg       0.64      0.54      0.57      7435\n",
      "weighted avg       0.81      0.83      0.81      7435\n",
      "\n",
      "KMeans\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.79      0.10       429\n",
      "           1       0.85      0.20      0.32      5757\n",
      "           2       0.00      0.00      0.00      1249\n",
      "\n",
      "    accuracy                           0.20      7435\n",
      "   macro avg       0.30      0.33      0.14      7435\n",
      "weighted avg       0.66      0.20      0.25      7435\n",
      "\n",
      "XGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.29       429\n",
      "           1       0.93      0.95      0.94      5757\n",
      "           2       0.83      0.89      0.86      1249\n",
      "\n",
      "    accuracy                           0.90      7435\n",
      "   macro avg       0.75      0.68      0.70      7435\n",
      "weighted avg       0.89      0.90      0.89      7435\n",
      "\n",
      "Support Vector Machine\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.08      0.13       429\n",
      "           1       0.92      0.96      0.94      5757\n",
      "           2       0.83      0.88      0.86      1249\n",
      "\n",
      "    accuracy                           0.90      7435\n",
      "   macro avg       0.76      0.64      0.64      7435\n",
      "weighted avg       0.88      0.90      0.88      7435\n",
      "\n",
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.26      0.30       429\n",
      "           1       0.93      0.93      0.93      5757\n",
      "           2       0.81      0.88      0.85      1249\n",
      "\n",
      "    accuracy                           0.89      7435\n",
      "   macro avg       0.70      0.69      0.69      7435\n",
      "weighted avg       0.88      0.89      0.88      7435\n",
      "\n",
      "kNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.44      0.11       429\n",
      "           1       0.81      0.37      0.51      5757\n",
      "           2       0.21      0.31      0.25      1249\n",
      "\n",
      "    accuracy                           0.37      7435\n",
      "   macro avg       0.36      0.37      0.29      7435\n",
      "weighted avg       0.66      0.37      0.44      7435\n",
      "\n",
      "SGD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       429\n",
      "           1       0.79      1.00      0.88      5757\n",
      "           2       0.82      0.09      0.16      1249\n",
      "\n",
      "    accuracy                           0.79      7435\n",
      "   macro avg       0.54      0.36      0.35      7435\n",
      "weighted avg       0.75      0.79      0.71      7435\n",
      "\n",
      "adaboost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.14      0.21       429\n",
      "           1       0.93      0.93      0.93      5757\n",
      "           2       0.73      0.91      0.81      1249\n",
      "\n",
      "    accuracy                           0.88      7435\n",
      "   macro avg       0.71      0.66      0.65      7435\n",
      "weighted avg       0.87      0.88      0.87      7435\n",
      "\n",
      "Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bhavya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.06      0.11       429\n",
      "           1       0.87      0.98      0.92      5757\n",
      "           2       0.87      0.60      0.71      1249\n",
      "\n",
      "    accuracy                           0.86      7435\n",
      "   macro avg       0.79      0.55      0.58      7435\n",
      "weighted avg       0.85      0.86      0.84      7435\n",
      "\n",
      "--------------------VotingClassifier--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.60331   0.17016   0.26545       429\n",
      "           1    0.92041   0.96422   0.94181      5757\n",
      "           2    0.84489   0.86789   0.85624      1249\n",
      "\n",
      "    accuracy                        0.90222      7435\n",
      "   macro avg    0.78954   0.66742   0.68783      7435\n",
      "weighted avg    0.88943   0.90222   0.88841      7435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=df['cleaned_text4'].values\n",
    "vectorizer = TfidfVectorizer()  \n",
    "x = vectorizer.fit_transform(x)\n",
    "y=df['class']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=51,stratify=y)\n",
    "models = dict()\n",
    "results=dict()\n",
    "models['Linear Regression'] = LogisticRegression(max_iter=5000)\n",
    "models['Multinomial Naive Bayes'] = MultinomialNB()\n",
    "models['Complement Naive Bayes'] = ComplementNB(force_alpha=True)\n",
    "models['KMeans'] = KMeans(n_clusters=2, n_init=10, random_state=59)\n",
    "models['XGB']= XGBClassifier(n_estimators=500)\n",
    "models['Support Vector Machine'] = SVC(kernel = 'sigmoid', gamma='scale',probability=True)\n",
    "models['Decision Tree'] = DecisionTreeClassifier(max_depth=100)\n",
    "models['kNN'] = KNeighborsClassifier()\n",
    "models['SGD']=SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=100, tol=None)\n",
    "models['adaboost']=AdaBoostClassifier()\n",
    "models['Random Forest'] = RandomForestClassifier(n_estimators=100)\n",
    "print(\"Training Models:\\n\")\n",
    "for model in models:\n",
    "        models[model].fit(x_train,y_train)\n",
    "        print(\"model \"+str(model)+\" trained\")\n",
    "print(\"Test Set Prediction:\\n\")\n",
    "model_names,accuracies,precisions_w,recalls_w,f1_scores_w,precisions_m,recalls_m,f1_scores_m = [],[],[],[],[],[],[],[]\n",
    "for i in models:\n",
    "        print(i)\n",
    "        y_pred=models[i].predict(x_test)\n",
    "        print(classification_report(y_test,y_pred))\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        if i!='SGD':\n",
    "                results[models[i]]=accuracy\n",
    "        precision_w = precision_score(y_test, y_pred,average='weighted')\n",
    "        recall_w = recall_score(y_test, y_pred,average='weighted')\n",
    "        f1_w = f1_score(y_test, y_pred,average='weighted')\n",
    "        precision_m = precision_score(y_test, y_pred,average='macro')\n",
    "        recall_m = recall_score(y_test, y_pred,average='macro')\n",
    "        f1_m = f1_score(y_test, y_pred,average='macro')\n",
    "        model_names.append(i)\n",
    "        accuracies.append(accuracy)\n",
    "        precisions_w.append(precision_w)\n",
    "        recalls_w.append(recall_w)\n",
    "        f1_scores_w.append(f1_w)\n",
    "        precisions_m.append(precision_m)\n",
    "        recalls_m.append(recall_m)\n",
    "        f1_scores_m.append(f1_m)\n",
    "top_3_keys_bow = sorted(results, key=lambda k: results[k], reverse=True)[:3]\n",
    "c1=top_3_keys_bow[0]\n",
    "c2=top_3_keys_bow[1]\n",
    "c3=top_3_keys_bow[2]\n",
    "models['ensemble voting'] = VotingClassifier (estimators=[('clf1',c1), ('clf2',c2),('clf3',c3)], voting='soft')\n",
    "models['ensemble voting'].fit(x_train, y_train)\n",
    "y_pred = models['ensemble voting'].predict(x_test)\n",
    "print('-'*20+'VotingClassifier'+'-'*20)\n",
    "print(classification_report(y_test, y_pred,digits=5))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_w = precision_score(y_test, y_pred,average='weighted')\n",
    "recall_w = recall_score(y_test, y_pred,average='weighted')\n",
    "f1_w = f1_score(y_test, y_pred,average='weighted')\n",
    "precision_m = precision_score(y_test, y_pred,average='macro')\n",
    "recall_m = recall_score(y_test, y_pred,average='macro')\n",
    "f1_m = f1_score(y_test, y_pred,average='macro')\n",
    "model_names.append('ensemble voting')\n",
    "accuracies.append(accuracy)\n",
    "precisions_w.append(precision_w)\n",
    "recalls_w.append(recall_w)\n",
    "f1_scores_w.append(f1_w)\n",
    "precisions_m.append(precision_m)\n",
    "recalls_m.append(recall_m)\n",
    "f1_scores_m.append(f1_m)\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model Name': model_names,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision Weighted': precisions_w,\n",
    "    'Recall Weighted': recalls_w,\n",
    "    'F1-Score Weighted': f1_scores_w,\n",
    "    'Precision Macro': precisions_m,\n",
    "    'Recall Macro': recalls_m,\n",
    "    'F1-Score Macro': f1_scores_m\n",
    "})\n",
    "metrics_df.sort_values(by=['Accuracy'], ascending=False, inplace=True)\n",
    "metrics_df.to_csv(\"TFIDF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(r\"C:\\Users\\Bhavya\\Desktop\\HateSpeechDataset\\glove2.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0] \n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Linear Regression--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       103\n",
      "           1    0.78407   1.00000   0.87897       374\n",
      "\n",
      "    accuracy                        0.78407       477\n",
      "   macro avg    0.39203   0.50000   0.43948       477\n",
      "weighted avg    0.61476   0.78407   0.68917       477\n",
      "\n",
      "--------------------KMeans--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.21250   0.49515   0.29738       103\n",
      "           1    0.78059   0.49465   0.60556       374\n",
      "\n",
      "    accuracy                        0.49476       477\n",
      "   macro avg    0.49655   0.49490   0.45147       477\n",
      "weighted avg    0.65792   0.49476   0.53902       477\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------XGB--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.55556   0.14563   0.23077       103\n",
      "           1    0.80444   0.96791   0.87864       374\n",
      "\n",
      "    accuracy                        0.79036       477\n",
      "   macro avg    0.68000   0.55677   0.55471       477\n",
      "weighted avg    0.75070   0.79036   0.73874       477\n",
      "\n",
      "--------------------Support Vector Machine--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       103\n",
      "           1    0.78407   1.00000   0.87897       374\n",
      "\n",
      "    accuracy                        0.78407       477\n",
      "   macro avg    0.39203   0.50000   0.43948       477\n",
      "weighted avg    0.61476   0.78407   0.68917       477\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Decision Tree--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.26829   0.32039   0.29204       103\n",
      "           1    0.80226   0.75936   0.78022       374\n",
      "\n",
      "    accuracy                        0.66457       477\n",
      "   macro avg    0.53528   0.53987   0.53613       477\n",
      "weighted avg    0.68696   0.66457   0.67480       477\n",
      "\n",
      "--------------------kNN--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.29167   0.06796   0.11024       103\n",
      "           1    0.78808   0.95455   0.86336       374\n",
      "\n",
      "    accuracy                        0.76310       477\n",
      "   macro avg    0.53987   0.51125   0.48680       477\n",
      "weighted avg    0.68089   0.76310   0.70074       477\n",
      "\n",
      "--------------------SGD--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       103\n",
      "           1    0.78407   1.00000   0.87897       374\n",
      "\n",
      "    accuracy                        0.78407       477\n",
      "   macro avg    0.39203   0.50000   0.43948       477\n",
      "weighted avg    0.61476   0.78407   0.68917       477\n",
      "\n",
      "Top 3 keys with the highest values:\n",
      "[XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=5000, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), LogisticRegression(max_iter=5000), SVC(kernel='sigmoid', probability=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.03883   0.07477       103\n",
      "           1    0.79070   1.00000   0.88312       374\n",
      "\n",
      "    accuracy                        0.79245       477\n",
      "   macro avg    0.89535   0.51942   0.47894       477\n",
      "weighted avg    0.83589   0.79245   0.70857       477\n",
      "\n",
      "--------------------Linear Regression--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.70968   0.06627   0.12121       332\n",
      "           1    0.76154   0.99099   0.86124       999\n",
      "\n",
      "    accuracy                        0.76033      1331\n",
      "   macro avg    0.73561   0.52863   0.49123      1331\n",
      "weighted avg    0.74860   0.76033   0.67665      1331\n",
      "\n",
      "--------------------KMeans--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.23460   0.48193   0.31558       332\n",
      "           1    0.73498   0.47748   0.57888       999\n",
      "\n",
      "    accuracy                        0.47859      1331\n",
      "   macro avg    0.48479   0.47970   0.44723      1331\n",
      "weighted avg    0.61017   0.47859   0.51321      1331\n",
      "\n",
      "--------------------XGB--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.72152   0.34337   0.46531       332\n",
      "           1    0.81415   0.95596   0.87937       999\n",
      "\n",
      "    accuracy                        0.80316      1331\n",
      "   macro avg    0.76784   0.64966   0.67234      1331\n",
      "weighted avg    0.79105   0.80316   0.77609      1331\n",
      "\n",
      "--------------------Support Vector Machine--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       332\n",
      "           1    0.75056   1.00000   0.85751       999\n",
      "\n",
      "    accuracy                        0.75056      1331\n",
      "   macro avg    0.37528   0.50000   0.42876      1331\n",
      "weighted avg    0.56335   0.75056   0.64362      1331\n",
      "\n",
      "--------------------Decision Tree--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.42980   0.45181   0.44053       332\n",
      "           1    0.81466   0.80080   0.80767       999\n",
      "\n",
      "    accuracy                        0.71375      1331\n",
      "   macro avg    0.62223   0.62630   0.62410      1331\n",
      "weighted avg    0.71866   0.71375   0.71609      1331\n",
      "\n",
      "--------------------kNN--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.57895   0.16566   0.25761       332\n",
      "           1    0.77589   0.95996   0.85817       999\n",
      "\n",
      "    accuracy                        0.76183      1331\n",
      "   macro avg    0.67742   0.56281   0.55789      1331\n",
      "weighted avg    0.72677   0.76183   0.70837      1331\n",
      "\n",
      "--------------------SGD--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       332\n",
      "           1    0.75056   1.00000   0.85751       999\n",
      "\n",
      "    accuracy                        0.75056      1331\n",
      "   macro avg    0.37528   0.50000   0.42876      1331\n",
      "weighted avg    0.56335   0.75056   0.64362      1331\n",
      "\n",
      "Top 3 keys with the highest values:\n",
      "[XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=5000, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), KNeighborsClassifier(), LogisticRegression(max_iter=5000)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80769   0.25301   0.38532       332\n",
      "           1    0.79788   0.97998   0.87960       999\n",
      "\n",
      "    accuracy                        0.79865      1331\n",
      "   macro avg    0.80279   0.61650   0.63246      1331\n",
      "weighted avg    0.80033   0.79865   0.75631      1331\n",
      "\n",
      "--------------------Linear Regression--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.66667   0.04181   0.07869       287\n",
      "           1    0.79385   0.99437   0.88287      1065\n",
      "\n",
      "    accuracy                        0.79216      1352\n",
      "   macro avg    0.73026   0.51809   0.48078      1352\n",
      "weighted avg    0.76685   0.79216   0.71216      1352\n",
      "\n",
      "--------------------KMeans--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.25262   0.58885   0.35356       287\n",
      "           1    0.82723   0.53052   0.64645      1065\n",
      "\n",
      "    accuracy                        0.54290      1352\n",
      "   macro avg    0.53992   0.55968   0.50000      1352\n",
      "weighted avg    0.70525   0.54290   0.58428      1352\n",
      "\n",
      "--------------------XGB--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.69643   0.27178   0.39098       287\n",
      "           1    0.83145   0.96808   0.89458      1065\n",
      "\n",
      "    accuracy                        0.82027      1352\n",
      "   macro avg    0.76394   0.61993   0.64278      1352\n",
      "weighted avg    0.80279   0.82027   0.78767      1352\n",
      "\n",
      "--------------------Support Vector Machine--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       287\n",
      "           1    0.78772   1.00000   0.88126      1065\n",
      "\n",
      "    accuracy                        0.78772      1352\n",
      "   macro avg    0.39386   0.50000   0.44063      1352\n",
      "weighted avg    0.62051   0.78772   0.69419      1352\n",
      "\n",
      "--------------------Decision Tree--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.40952   0.44948   0.42857       287\n",
      "           1    0.84764   0.82535   0.83635      1065\n",
      "\n",
      "    accuracy                        0.74556      1352\n",
      "   macro avg    0.62858   0.63741   0.63246      1352\n",
      "weighted avg    0.75464   0.74556   0.74978      1352\n",
      "\n",
      "--------------------kNN--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.56471   0.16725   0.25806       287\n",
      "           1    0.81137   0.96526   0.88165      1065\n",
      "\n",
      "    accuracy                        0.79586      1352\n",
      "   macro avg    0.68804   0.56625   0.56986      1352\n",
      "weighted avg    0.75901   0.79586   0.74927      1352\n",
      "\n",
      "--------------------SGD--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       287\n",
      "           1    0.78772   1.00000   0.88126      1065\n",
      "\n",
      "    accuracy                        0.78772      1352\n",
      "   macro avg    0.39386   0.50000   0.44063      1352\n",
      "weighted avg    0.62051   0.78772   0.69419      1352\n",
      "\n",
      "Top 3 keys with the highest values:\n",
      "[XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=5000, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), KNeighborsClassifier(), LogisticRegression(max_iter=5000)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81081   0.20906   0.33241       287\n",
      "           1    0.82238   0.98685   0.89714      1065\n",
      "\n",
      "    accuracy                        0.82175      1352\n",
      "   macro avg    0.81659   0.59796   0.61478      1352\n",
      "weighted avg    0.81992   0.82175   0.77726      1352\n",
      "\n",
      "--------------------Linear Regression--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.58633   0.31712   0.41162       514\n",
      "           1    0.67769   0.86518   0.76004       853\n",
      "\n",
      "    accuracy                        0.65911      1367\n",
      "   macro avg    0.63201   0.59115   0.58583      1367\n",
      "weighted avg    0.64334   0.65911   0.62903      1367\n",
      "\n",
      "--------------------KMeans--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.29037   0.39883   0.33607       514\n",
      "           1    0.53253   0.41266   0.46499       853\n",
      "\n",
      "    accuracy                        0.40746      1367\n",
      "   macro avg    0.41145   0.40575   0.40053      1367\n",
      "weighted avg    0.44147   0.40746   0.41652      1367\n",
      "\n",
      "--------------------XGB--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.64548   0.51362   0.57205       514\n",
      "           1    0.73904   0.83001   0.78189       853\n",
      "\n",
      "    accuracy                        0.71105      1367\n",
      "   macro avg    0.69226   0.67182   0.67697      1367\n",
      "weighted avg    0.70386   0.71105   0.70299      1367\n",
      "\n",
      "--------------------Support Vector Machine--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       514\n",
      "           1    0.62399   1.00000   0.76847       853\n",
      "\n",
      "    accuracy                        0.62399      1367\n",
      "   macro avg    0.31200   0.50000   0.38423      1367\n",
      "weighted avg    0.38937   0.62399   0.47952      1367\n",
      "\n",
      "--------------------Decision Tree--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.52652   0.54086   0.53359       514\n",
      "           1    0.71871   0.70692   0.71277       853\n",
      "\n",
      "    accuracy                        0.64448      1367\n",
      "   macro avg    0.62261   0.62389   0.62318      1367\n",
      "weighted avg    0.64645   0.64448   0.64539      1367\n",
      "\n",
      "--------------------kNN--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.53560   0.33658   0.41338       514\n",
      "           1    0.67337   0.82415   0.74117       853\n",
      "\n",
      "    accuracy                        0.64082      1367\n",
      "   macro avg    0.60449   0.58036   0.57728      1367\n",
      "weighted avg    0.62157   0.64082   0.61792      1367\n",
      "\n",
      "--------------------SGD--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.59314   0.23541   0.33705       514\n",
      "           1    0.66208   0.90270   0.76389       853\n",
      "\n",
      "    accuracy                        0.65179      1367\n",
      "   macro avg    0.62761   0.56905   0.55047      1367\n",
      "weighted avg    0.63616   0.65179   0.60339      1367\n",
      "\n",
      "Top 3 keys with the highest values:\n",
      "[XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=5000, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), LogisticRegression(max_iter=5000), DecisionTreeClassifier(max_depth=100)]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.63830   0.52529   0.57631       514\n",
      "           1    0.74153   0.82063   0.77908       853\n",
      "\n",
      "    accuracy                        0.70958      1367\n",
      "   macro avg    0.68991   0.67296   0.67769      1367\n",
      "weighted avg    0.70271   0.70958   0.70283      1367\n",
      "\n",
      "--------------------Linear Regression--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000        31\n",
      "           1    0.82778   1.00000   0.90578       149\n",
      "\n",
      "    accuracy                        0.82778       180\n",
      "   macro avg    0.41389   0.50000   0.45289       180\n",
      "weighted avg    0.68522   0.82778   0.74978       180\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------KMeans--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.15730   0.45161   0.23333        31\n",
      "           1    0.81319   0.49664   0.61667       149\n",
      "\n",
      "    accuracy                        0.48889       180\n",
      "   macro avg    0.48525   0.47413   0.42500       180\n",
      "weighted avg    0.70023   0.48889   0.55065       180\n",
      "\n",
      "--------------------XGB--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.78571   0.35484   0.48889        31\n",
      "           1    0.87952   0.97987   0.92698       149\n",
      "\n",
      "    accuracy                        0.87222       180\n",
      "   macro avg    0.83262   0.66735   0.70794       180\n",
      "weighted avg    0.86336   0.87222   0.85153       180\n",
      "\n",
      "--------------------Support Vector Machine--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000        31\n",
      "           1    0.82778   1.00000   0.90578       149\n",
      "\n",
      "    accuracy                        0.82778       180\n",
      "   macro avg    0.41389   0.50000   0.45289       180\n",
      "weighted avg    0.68522   0.82778   0.74978       180\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Decision Tree--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.45161   0.45161   0.45161        31\n",
      "           1    0.88591   0.88591   0.88591       149\n",
      "\n",
      "    accuracy                        0.81111       180\n",
      "   macro avg    0.66876   0.66876   0.66876       180\n",
      "weighted avg    0.81111   0.81111   0.81111       180\n",
      "\n",
      "--------------------kNN--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.41667   0.16129   0.23256        31\n",
      "           1    0.84524   0.95302   0.89590       149\n",
      "\n",
      "    accuracy                        0.81667       180\n",
      "   macro avg    0.63095   0.55716   0.56423       180\n",
      "weighted avg    0.77143   0.81667   0.78166       180\n",
      "\n",
      "--------------------SGD--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000        31\n",
      "           1    0.82778   1.00000   0.90578       149\n",
      "\n",
      "    accuracy                        0.82778       180\n",
      "   macro avg    0.41389   0.50000   0.45289       180\n",
      "weighted avg    0.68522   0.82778   0.74978       180\n",
      "\n",
      "Top 3 keys with the highest values:\n",
      "[XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=5000, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), LogisticRegression(max_iter=5000), SVC(kernel='sigmoid', probability=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000        31\n",
      "           1    0.82778   1.00000   0.90578       149\n",
      "\n",
      "    accuracy                        0.82778       180\n",
      "   macro avg    0.41389   0.50000   0.45289       180\n",
      "weighted avg    0.68522   0.82778   0.74978       180\n",
      "\n",
      "--------------------Linear Regression--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.00952   0.01887       105\n",
      "           1    0.74818   1.00000   0.85596       309\n",
      "\n",
      "    accuracy                        0.74879       414\n",
      "   macro avg    0.87409   0.50476   0.43741       414\n",
      "weighted avg    0.81205   0.74879   0.64365       414\n",
      "\n",
      "--------------------KMeans--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.26818   0.56190   0.36308       105\n",
      "           1    0.76289   0.47896   0.58847       309\n",
      "\n",
      "    accuracy                        0.50000       414\n",
      "   macro avg    0.51553   0.52043   0.47577       414\n",
      "weighted avg    0.63742   0.50000   0.53130       414\n",
      "\n",
      "--------------------XGB--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.45000   0.25714   0.32727       105\n",
      "           1    0.77966   0.89320   0.83258       309\n",
      "\n",
      "    accuracy                        0.73188       414\n",
      "   macro avg    0.61483   0.57517   0.57993       414\n",
      "weighted avg    0.69605   0.73188   0.70442       414\n",
      "\n",
      "--------------------Support Vector Machine--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       105\n",
      "           1    0.74638   1.00000   0.85477       309\n",
      "\n",
      "    accuracy                        0.74638       414\n",
      "   macro avg    0.37319   0.50000   0.42739       414\n",
      "weighted avg    0.55708   0.74638   0.63798       414\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Decision Tree--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.35246   0.40952   0.37885       105\n",
      "           1    0.78767   0.74434   0.76539       309\n",
      "\n",
      "    accuracy                        0.65942       414\n",
      "   macro avg    0.57007   0.57693   0.57212       414\n",
      "weighted avg    0.67729   0.65942   0.66736       414\n",
      "\n",
      "--------------------kNN--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.47826   0.20952   0.29139       105\n",
      "           1    0.77446   0.92233   0.84195       309\n",
      "\n",
      "    accuracy                        0.74155       414\n",
      "   macro avg    0.62636   0.56593   0.56667       414\n",
      "weighted avg    0.69933   0.74155   0.70232       414\n",
      "\n",
      "--------------------SGD--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       105\n",
      "           1    0.74638   1.00000   0.85477       309\n",
      "\n",
      "    accuracy                        0.74638       414\n",
      "   macro avg    0.37319   0.50000   0.42739       414\n",
      "weighted avg    0.55708   0.74638   0.63798       414\n",
      "\n",
      "Top 3 keys with the highest values:\n",
      "[LogisticRegression(max_iter=5000), SVC(kernel='sigmoid', probability=True), KNeighborsClassifier()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.50000   0.00952   0.01869       105\n",
      "           1    0.74757   0.99676   0.85437       309\n",
      "\n",
      "    accuracy                        0.74638       414\n",
      "   macro avg    0.62379   0.50314   0.43653       414\n",
      "weighted avg    0.68478   0.74638   0.64242       414\n",
      "\n",
      "--------------------Linear Regression--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80804   0.91878   0.85986       197\n",
      "           1    0.80723   0.60909   0.69430       110\n",
      "\n",
      "    accuracy                        0.80782       307\n",
      "   macro avg    0.80763   0.76394   0.77708       307\n",
      "weighted avg    0.80775   0.80782   0.80054       307\n",
      "\n",
      "--------------------KMeans--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.65476   0.55838   0.60274       197\n",
      "           1    0.37410   0.47273   0.41767       110\n",
      "\n",
      "    accuracy                        0.52769       307\n",
      "   macro avg    0.51443   0.51555   0.51021       307\n",
      "weighted avg    0.55420   0.52769   0.53643       307\n",
      "\n",
      "--------------------XGB--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85000   0.94924   0.89688       197\n",
      "           1    0.88506   0.70000   0.78173       110\n",
      "\n",
      "    accuracy                        0.85993       307\n",
      "   macro avg    0.86753   0.82462   0.83930       307\n",
      "weighted avg    0.86256   0.85993   0.85562       307\n",
      "\n",
      "--------------------Support Vector Machine--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.64169   1.00000   0.78175       197\n",
      "           1    0.00000   0.00000   0.00000       110\n",
      "\n",
      "    accuracy                        0.64169       307\n",
      "   macro avg    0.32085   0.50000   0.39087       307\n",
      "weighted avg    0.41177   0.64169   0.50164       307\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aditya Joshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Decision Tree--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81407   0.82234   0.81818       197\n",
      "           1    0.67593   0.66364   0.66972       110\n",
      "\n",
      "    accuracy                        0.76547       307\n",
      "   macro avg    0.74500   0.74299   0.74395       307\n",
      "weighted avg    0.76457   0.76547   0.76499       307\n",
      "\n",
      "--------------------kNN--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85795   0.76650   0.80965       197\n",
      "           1    0.64885   0.77273   0.70539       110\n",
      "\n",
      "    accuracy                        0.76873       307\n",
      "   macro avg    0.75340   0.76961   0.75752       307\n",
      "weighted avg    0.78303   0.76873   0.77230       307\n",
      "\n",
      "--------------------SGD--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83673   0.83249   0.83461       197\n",
      "           1    0.70270   0.70909   0.70588       110\n",
      "\n",
      "    accuracy                        0.78827       307\n",
      "   macro avg    0.76972   0.77079   0.77024       307\n",
      "weighted avg    0.78871   0.78827   0.78848       307\n",
      "\n",
      "Top 3 keys with the highest values:\n",
      "[XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=5000, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), LogisticRegression(max_iter=5000), KNeighborsClassifier()]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85068   0.95431   0.89952       197\n",
      "           1    0.89535   0.70000   0.78571       110\n",
      "\n",
      "    accuracy                        0.86319       307\n",
      "   macro avg    0.87301   0.82716   0.84262       307\n",
      "weighted avg    0.86668   0.86319   0.85874       307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts=df['cleaned_text4'].astype(str)\n",
    "embeddings = []\n",
    "n=0\n",
    "ex=[]\n",
    "for text in texts:\n",
    "    text_embedding = []\n",
    "    for word in text:\n",
    "        if word in embeddings_index:\n",
    "            text_embedding.append(embeddings_index[word])\n",
    "    if len(text_embedding) > 0:\n",
    "        text_embedding = np.mean(text_embedding, axis=0)\n",
    "        embeddings.append(text_embedding)\n",
    "    else:\n",
    "        embeddings.append(np.zeros(300))\n",
    "    n+=1\n",
    "embeddings = np.array(embeddings)\n",
    "len(embeddings)\n",
    "\n",
    "y=df['class']\n",
    "x_train,x_test,y_train,y_test=train_test_split(embeddings,y,test_size=0.3,stratify=y,random_state=51)\n",
    "models = dict()\n",
    "results=dict()\n",
    "model_names,accuracies,precisions_w,recalls_w,f1_scores_w,precisions_m,recalls_m,f1_scores_m = [],[],[],[],[],[],[],[]\n",
    "models['Linear Regression'] = LogisticRegression(max_iter=5000)\n",
    "models['KMeans'] = KMeans(n_clusters=2, n_init=10, random_state=59)\n",
    "models['XGB']= XGBClassifier(n_estimators=5000)\n",
    "models['Support Vector Machine'] = SVC(kernel = 'sigmoid', gamma='scale',probability=True)\n",
    "models['Decision Tree'] = DecisionTreeClassifier(max_depth=100)\n",
    "models['kNN'] = KNeighborsClassifier()\n",
    "models['SGD']=SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=100, tol=None)\n",
    "for i in models:\n",
    "    models[i].fit(x_train,y_train)\n",
    "    print('-'*20+i+'-'*20)\n",
    "    y_pred=models[i].predict(x_test)\n",
    "    if i!='SGD' and i!='KMeans':\n",
    "        results[models[i]]=accuracy_score(y_test, y_pred)\n",
    "    print(classification_report(y_test,y_pred,digits=5))\n",
    "    model_names.append(i)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    precisions_w.append(precision_score(y_test, y_pred,average='weighted'))\n",
    "    recalls_w.append(recall_score(y_test, y_pred,average='weighted'))\n",
    "    f1_scores_w.append(f1_score(y_test, y_pred,average='weighted'))\n",
    "    precisions_m.append(precision_score(y_test, y_pred,average='macro'))\n",
    "    recalls_m.append(recall_score(y_test, y_pred,average='macro'))\n",
    "    f1_scores_m.append(f1_score(y_test, y_pred,average='macro'))\n",
    "top_3_keys_tf = sorted(results, key=lambda k: results[k], reverse=True)[:3]\n",
    "print(\"Top 3 keys with the highest values:\")\n",
    "print(top_3_keys_tf)\n",
    "c1=top_3_keys_tf[0]\n",
    "c2=top_3_keys_tf[1]\n",
    "c3=top_3_keys_tf[2]\n",
    "i='ensemble voting'\n",
    "models['ensemble voting'] = VotingClassifier (estimators=[('clf1',c1), ('clf2',c2),('clf3',c3)], voting='soft')\n",
    "models['ensemble voting'].fit(x_train, y_train)\n",
    "y_pred = models['ensemble voting'].predict(x_test)\n",
    "y_pred=models[i].predict(x_test)\n",
    "print(classification_report(y_test,y_pred,digits=5))\n",
    "model_names.append(i)\n",
    "accuracies.append(accuracy_score(y_test, y_pred))\n",
    "precisions_w.append(precision_score(y_test, y_pred,average='weighted'))\n",
    "recalls_w.append(recall_score(y_test, y_pred,average='weighted'))\n",
    "f1_scores_w.append(f1_score(y_test, y_pred,average='weighted'))\n",
    "precisions_m.append(precision_score(y_test, y_pred,average='macro'))\n",
    "recalls_m.append(recall_score(y_test, y_pred,average='macro'))\n",
    "f1_scores_m.append(f1_score(y_test, y_pred,average='macro'))\n",
    "metrics_df = pd.DataFrame({\n",
    "'Model Name': model_names,\n",
    "'Accuracy': accuracies,\n",
    "'Precision Weighted': precisions_w,\n",
    "'Recall Weighted': recalls_w,\n",
    "'F1-Score Weighted': f1_scores_w,\n",
    "'Precision Macro': precisions_m,\n",
    "'Recall Macro': recalls_m,\n",
    "'F1-Score Macro': f1_scores_m\n",
    "})\n",
    "metrics_df.sort_values(by=['Accuracy'], ascending=False, inplace=True)\n",
    "metrics_df.to_csv(\"glove.csv\", index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
